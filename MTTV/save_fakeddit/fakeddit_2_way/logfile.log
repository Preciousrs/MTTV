INFO - 06/12/24 12:10:26 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/Fakeddit/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/12/24 12:10:26 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:10:28 - 0:00:02 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:10:28 - 0:00:02 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO - 06/12/24 12:12:12 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/fakeddit/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/12/24 12:12:12 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:12:13 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:12:13 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO - 06/12/24 12:12:28 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/12/24 12:12:28 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:12:29 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:12:29 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/12/24 12:12:29 - 0:00:01 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:12:31 - 0:00:02 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:12:31 - 0:00:02 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/12/24 12:12:31 - 0:00:02 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:12:39 - 0:00:10 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased.tar.gz HTTP/1.1" 200 0
INFO - 06/12/24 12:12:39 - 0:00:10 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/12/24 12:12:39 - 0:00:10 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp1hbpk_ex
INFO - 06/12/24 12:12:42 - 0:00:14 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/12/24 12:12:45 - 0:00:17 - Training..
INFO - 06/12/24 12:12:45 - 0:00:17 - Epoch	1
INFO - 06/12/24 12:16:12 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/12/24 12:16:12 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:16:13 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:16:13 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/12/24 12:16:13 - 0:00:01 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:16:14 - 0:00:02 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:16:14 - 0:00:02 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/12/24 12:16:14 - 0:00:02 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:16:15 - 0:00:03 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased.tar.gz HTTP/1.1" 200 0
INFO - 06/12/24 12:16:15 - 0:00:03 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/12/24 12:16:15 - 0:00:03 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpu_7yk5ry
INFO - 06/12/24 12:16:19 - 0:00:06 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/12/24 12:16:22 - 0:00:10 - Training..
INFO - 06/12/24 12:16:22 - 0:00:10 - Epoch	1
INFO - 06/12/24 12:17:36 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/12/24 12:17:36 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:17:37 - 0:00:02 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:17:37 - 0:00:02 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/12/24 12:17:38 - 0:00:02 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:17:39 - 0:00:03 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/12/24 12:17:39 - 0:00:03 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/12/24 12:17:39 - 0:00:03 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/12/24 12:17:40 - 0:00:04 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased.tar.gz HTTP/1.1" 200 0
INFO - 06/12/24 12:17:40 - 0:00:04 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/12/24 12:17:40 - 0:00:04 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpdg93seud
INFO - 06/12/24 12:17:43 - 0:00:07 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/12/24 12:17:46 - 0:00:11 - Training..
INFO - 06/12/24 12:17:46 - 0:00:11 - Epoch	1
INFO - 06/12/24 12:18:12 - 0:00:36 - Train Loss: 0.0348
INFO - 06/12/24 12:18:12 - 0:00:36 - Val: Loss: 0.66726 | Acc: 0.56877
INFO - 06/12/24 12:18:14 - 0:00:39 - Test: Loss: 0.66637 | Acc: 0.58749
INFO - 06/12/24 12:18:17 - 0:00:41 - Epoch	2
INFO - 06/12/24 12:18:42 - 0:01:06 - Train Loss: 0.0352
INFO - 06/12/24 12:18:42 - 0:01:06 - Val: Loss: 0.70497 | Acc: 0.46617
INFO - 06/12/24 12:18:44 - 0:01:08 - Test: Loss: 0.70873 | Acc: 0.44210
INFO - 06/12/24 12:18:46 - 0:01:10 - Epoch	3
INFO - 06/12/24 12:19:11 - 0:01:35 - Train Loss: 0.0346
INFO - 06/12/24 12:19:11 - 0:01:35 - Val: Loss: 0.54858 | Acc: 0.74201
INFO - 06/12/24 12:19:13 - 0:01:37 - Test: Loss: 0.57552 | Acc: 0.72020
INFO - 06/12/24 12:19:23 - 0:01:47 - Epoch	4
INFO - 06/12/24 12:19:49 - 0:02:13 - Train Loss: 0.0357
INFO - 06/12/24 12:19:49 - 0:02:13 - Val: Loss: 0.69178 | Acc: 0.53903
INFO - 06/12/24 12:19:51 - 0:02:15 - Test: Loss: 0.68627 | Acc: 0.56382
INFO - 06/12/24 12:19:52 - 0:02:16 - Epoch	5
INFO - 06/12/24 12:20:18 - 0:02:42 - Train Loss: 0.0355
INFO - 06/12/24 12:20:18 - 0:02:42 - Val: Loss: 0.68994 | Acc: 0.53903
INFO - 06/12/24 12:20:20 - 0:02:44 - Test: Loss: 0.68921 | Acc: 0.56382
INFO - 06/12/24 12:20:21 - 0:02:45 - Epoch	6
INFO - 06/12/24 12:20:46 - 0:03:10 - Train Loss: 0.0347
INFO - 06/12/24 12:20:46 - 0:03:10 - Val: Loss: 0.68831 | Acc: 0.53903
INFO - 06/12/24 12:20:48 - 0:03:12 - Test: Loss: 0.68481 | Acc: 0.56382
INFO - 06/12/24 12:20:50 - 0:03:14 - Epoch	7
INFO - 06/12/24 12:21:15 - 0:03:39 - Train Loss: 0.0344
INFO - 06/12/24 12:21:15 - 0:03:39 - Val: Loss: 0.68724 | Acc: 0.53903
INFO - 06/12/24 12:21:17 - 0:03:41 - Test: Loss: 0.68513 | Acc: 0.56382
INFO - 06/12/24 12:21:19 - 0:03:43 - Epoch	8
INFO - 06/12/24 12:21:44 - 0:04:08 - Train Loss: 0.0343
INFO - 06/12/24 12:21:44 - 0:04:08 - Val: Loss: 0.68122 | Acc: 0.53903
INFO - 06/12/24 12:21:46 - 0:04:10 - Test: Loss: 0.67968 | Acc: 0.56382
INFO - 06/12/24 12:21:48 - 0:04:12 - Epoch	9
INFO - 06/12/24 12:22:13 - 0:04:37 - Train Loss: 0.0330
INFO - 06/12/24 12:22:13 - 0:04:37 - Val: Loss: 0.58127 | Acc: 0.71896
INFO - 06/12/24 12:22:15 - 0:04:39 - Test: Loss: 0.62591 | Acc: 0.63060
INFO - 06/12/24 12:22:16 - 0:04:40 - Epoch	10
INFO - 06/12/24 12:22:42 - 0:05:06 - Train Loss: 0.0271
INFO - 06/12/24 12:22:42 - 0:05:06 - Val: Loss: 0.56336 | Acc: 0.75539
INFO - 06/12/24 12:22:44 - 0:05:08 - Test: Loss: 0.63252 | Acc: 0.72443
INFO - 06/12/24 12:22:52 - 0:05:16 - Epoch	11
INFO - 06/12/24 12:23:18 - 0:05:42 - Train Loss: 0.0248
INFO - 06/12/24 12:23:18 - 0:05:42 - Val: Loss: 0.40892 | Acc: 0.83494
INFO - 06/12/24 12:23:20 - 0:05:44 - Test: Loss: 0.54469 | Acc: 0.73964
INFO - 06/12/24 12:23:26 - 0:05:50 - Epoch	12
INFO - 06/12/24 12:23:51 - 0:06:16 - Train Loss: 0.0222
INFO - 06/12/24 12:23:51 - 0:06:16 - Val: Loss: 0.43958 | Acc: 0.80595
INFO - 06/12/24 12:23:53 - 0:06:18 - Test: Loss: 0.57705 | Acc: 0.74725
INFO - 06/12/24 12:24:02 - 0:06:26 - Epoch	13
INFO - 06/12/24 12:24:27 - 0:06:51 - Train Loss: 0.0199
INFO - 06/12/24 12:24:27 - 0:06:51 - Val: Loss: 0.37587 | Acc: 0.84610
INFO - 06/12/24 12:24:29 - 0:06:53 - Test: Loss: 0.55698 | Acc: 0.76331
INFO - 06/12/24 12:24:35 - 0:06:59 - Epoch	14
INFO - 06/12/24 12:25:00 - 0:07:24 - Train Loss: 0.0184
INFO - 06/12/24 12:25:00 - 0:07:24 - Val: Loss: 0.35859 | Acc: 0.85651
INFO - 06/12/24 12:25:02 - 0:07:26 - Test: Loss: 0.55866 | Acc: 0.76923
INFO - 06/12/24 12:25:08 - 0:07:33 - Epoch	15
INFO - 06/12/24 12:25:34 - 0:07:58 - Train Loss: 0.0177
INFO - 06/12/24 12:25:34 - 0:07:58 - Val: Loss: 0.30468 | Acc: 0.88550
INFO - 06/12/24 12:25:36 - 0:08:00 - Test: Loss: 0.54195 | Acc: 0.77177
INFO - 06/12/24 12:25:42 - 0:08:06 - Epoch	16
INFO - 06/12/24 12:26:07 - 0:08:31 - Train Loss: 0.0167
INFO - 06/12/24 12:26:07 - 0:08:31 - Val: Loss: 0.30255 | Acc: 0.88550
INFO - 06/12/24 12:26:09 - 0:08:33 - Test: Loss: 0.55211 | Acc: 0.76500
INFO - 06/12/24 12:26:11 - 0:08:35 - Epoch	17
INFO - 06/12/24 12:26:36 - 0:09:00 - Train Loss: 0.0162
INFO - 06/12/24 12:26:36 - 0:09:00 - Val: Loss: 0.28402 | Acc: 0.89591
INFO - 06/12/24 12:26:38 - 0:09:02 - Test: Loss: 0.54629 | Acc: 0.77008
INFO - 06/12/24 12:26:39 - 0:09:03 - Epoch	18
INFO - 06/12/24 12:27:04 - 0:09:29 - Train Loss: 0.0153
INFO - 06/12/24 12:27:04 - 0:09:29 - Val: Loss: 0.28505 | Acc: 0.89294
INFO - 06/12/24 12:27:07 - 0:09:31 - Test: Loss: 0.56037 | Acc: 0.76923
INFO - 06/12/24 12:27:08 - 0:09:32 - Epoch	19
INFO - 06/12/24 12:27:33 - 0:09:58 - Train Loss: 0.0151
INFO - 06/12/24 12:27:33 - 0:09:58 - Val: Loss: 0.29603 | Acc: 0.88773
INFO - 06/12/24 12:27:36 - 0:10:00 - Test: Loss: 0.57473 | Acc: 0.76754
INFO - 06/12/24 12:27:37 - 0:10:01 - Epoch	20
INFO - 06/12/24 12:28:02 - 0:10:26 - Train Loss: 0.0150
INFO - 06/12/24 12:28:02 - 0:10:26 - Val: Loss: 0.29471 | Acc: 0.88922
INFO - 06/12/24 12:28:04 - 0:10:28 - Test: Loss: 0.57618 | Acc: 0.76669
INFO - 06/15/24 15:28:16 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/Fakeddit/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/15/24 15:28:16 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 15:28:18 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 15:28:18 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO - 06/15/24 15:28:56 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/fakeddit/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/15/24 15:28:56 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
INFO - 06/15/24 15:29:01 - 0:00:05 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO - 06/15/24 15:32:08 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/15/24 15:32:08 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
INFO - 06/15/24 15:32:13 - 0:00:05 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 15:32:13 - 0:00:05 - Starting new HTTPS connection (1): s3.amazonaws.com:443
INFO - 06/15/24 15:32:18 - 0:00:10 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 15:32:19 - 0:00:11 - Starting new HTTPS connection (1): s3.amazonaws.com:443
INFO - 06/15/24 15:32:24 - 0:00:16 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/15/24 15:32:24 - 0:00:16 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpvlxh0_7l
INFO - 06/15/24 15:32:27 - 0:00:19 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/15/24 15:32:30 - 0:00:22 - Training..
INFO - 06/15/24 15:32:30 - 0:00:22 - Epoch	1
INFO - 06/15/24 15:44:45 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 5
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 25
                                     patience: 10
                                     region_image_embeds: 20
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/15/24 15:44:45 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 15:44:46 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 15:44:46 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 15:44:46 - 0:00:01 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 15:44:48 - 0:00:03 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 15:44:48 - 0:00:03 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 15:44:48 - 0:00:03 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 15:44:50 - 0:00:05 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased.tar.gz HTTP/1.1" 200 0
INFO - 06/15/24 15:44:50 - 0:00:05 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/15/24 15:44:50 - 0:00:05 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgz0c1n17
INFO - 06/15/24 15:44:53 - 0:00:08 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/15/24 15:44:56 - 0:00:11 - Training..
INFO - 06/15/24 15:44:56 - 0:00:11 - Epoch	1
INFO - 06/15/24 15:46:34 - 0:01:49 - Train Loss: 0.0295
INFO - 06/15/24 15:46:34 - 0:01:49 - Val: Loss: 0.40026 | Acc: 0.82321
INFO - 06/15/24 15:46:43 - 0:01:58 - Test: Loss: 0.44144 | Acc: 0.79892
INFO - 06/15/24 15:46:53 - 0:02:08 - Epoch	2
INFO - 06/15/24 15:48:31 - 0:03:46 - Train Loss: 0.0198
INFO - 06/15/24 15:48:31 - 0:03:46 - Val: Loss: 0.23015 | Acc: 0.92482
INFO - 06/15/24 15:48:40 - 0:03:55 - Test: Loss: 0.39392 | Acc: 0.82366
INFO - 06/15/24 15:48:50 - 0:04:05 - Epoch	3
INFO - 06/15/24 15:50:28 - 0:05:43 - Train Loss: 0.0111
INFO - 06/15/24 15:50:28 - 0:05:43 - Val: Loss: 0.07647 | Acc: 0.97769
INFO - 06/15/24 15:50:37 - 0:05:52 - Test: Loss: 0.46120 | Acc: 0.82366
INFO - 06/15/24 15:50:42 - 0:05:57 - Epoch	4
INFO - 06/15/24 15:52:20 - 0:07:35 - Train Loss: 0.0044
INFO - 06/15/24 15:52:20 - 0:07:35 - Val: Loss: 0.02586 | Acc: 0.99306
INFO - 06/15/24 15:52:29 - 0:07:44 - Test: Loss: 0.63339 | Acc: 0.82254
INFO - 06/15/24 15:52:34 - 0:07:49 - Epoch	5
INFO - 06/15/24 15:54:12 - 0:09:27 - Train Loss: 0.0020
INFO - 06/15/24 15:54:12 - 0:09:27 - Val: Loss: 0.03003 | Acc: 0.99063
INFO - 06/15/24 15:54:21 - 0:09:36 - Test: Loss: 0.77774 | Acc: 0.81808
INFO - 06/15/24 15:54:25 - 0:09:40 - Epoch	6
INFO - 06/15/24 15:56:03 - 0:11:18 - Train Loss: 0.0012
INFO - 06/15/24 15:56:03 - 0:11:18 - Val: Loss: 0.00167 | Acc: 0.99981
INFO - 06/15/24 15:56:12 - 0:11:26 - Test: Loss: 0.86917 | Acc: 0.82236
INFO - 06/15/24 15:56:16 - 0:11:31 - Epoch	7
INFO - 06/15/24 15:57:53 - 0:13:08 - Train Loss: 0.0003
INFO - 06/15/24 15:57:53 - 0:13:08 - Val: Loss: 0.00085 | Acc: 0.99981
INFO - 06/15/24 15:58:02 - 0:13:17 - Test: Loss: 1.07123 | Acc: 0.82292
INFO - 06/15/24 15:58:06 - 0:13:21 - Epoch	8
INFO - 06/15/24 15:59:45 - 0:15:00 - Train Loss: 0.0002
INFO - 06/15/24 15:59:45 - 0:15:00 - Val: Loss: 0.00024 | Acc: 1.00000
INFO - 06/15/24 15:59:54 - 0:15:08 - Test: Loss: 1.07884 | Acc: 0.82645
INFO - 06/15/24 16:00:03 - 0:15:18 - Epoch	9
INFO - 06/15/24 16:01:41 - 0:16:56 - Train Loss: 0.0002
INFO - 06/15/24 16:01:41 - 0:16:56 - Val: Loss: 0.00031 | Acc: 1.00000
INFO - 06/15/24 16:01:50 - 0:17:05 - Test: Loss: 1.09292 | Acc: 0.82552
INFO - 06/15/24 16:01:55 - 0:17:10 - Epoch	10
INFO - 06/15/24 16:03:34 - 0:18:48 - Train Loss: 0.0001
INFO - 06/15/24 16:03:34 - 0:18:48 - Val: Loss: 0.00051 | Acc: 0.99981
INFO - 06/15/24 16:03:42 - 0:18:57 - Test: Loss: 1.13682 | Acc: 0.82031
INFO - 06/15/24 16:03:47 - 0:19:02 - Epoch	11
INFO - 06/15/24 16:05:25 - 0:20:40 - Train Loss: 0.0001
INFO - 06/15/24 16:05:25 - 0:20:40 - Val: Loss: 0.00016 | Acc: 1.00000
INFO - 06/15/24 16:05:35 - 0:20:50 - Test: Loss: 1.15453 | Acc: 0.82254
INFO - 06/15/24 16:05:40 - 0:20:55 - Epoch	12
INFO - 06/15/24 16:07:18 - 0:22:33 - Train Loss: 0.0001
INFO - 06/15/24 16:07:18 - 0:22:33 - Val: Loss: 0.00025 | Acc: 0.99981
INFO - 06/15/24 16:07:27 - 0:22:42 - Test: Loss: 1.15314 | Acc: 0.82738
INFO - 06/15/24 16:07:37 - 0:22:52 - Epoch	13
INFO - 06/15/24 16:09:15 - 0:24:30 - Train Loss: 0.0001
INFO - 06/15/24 16:09:15 - 0:24:30 - Val: Loss: 0.00021 | Acc: 1.00000
INFO - 06/15/24 16:09:24 - 0:24:39 - Test: Loss: 1.16105 | Acc: 0.82533
INFO - 06/15/24 16:09:29 - 0:24:44 - Epoch	14
INFO - 06/15/24 16:11:07 - 0:26:22 - Train Loss: 0.0000
INFO - 06/15/24 16:11:07 - 0:26:22 - Val: Loss: 0.00017 | Acc: 1.00000
INFO - 06/15/24 16:11:15 - 0:26:30 - Test: Loss: 1.17419 | Acc: 0.82571
INFO - 06/15/24 16:11:20 - 0:26:35 - Epoch	15
INFO - 06/15/24 16:12:58 - 0:28:13 - Train Loss: 0.0001
INFO - 06/15/24 16:12:58 - 0:28:13 - Val: Loss: 0.00013 | Acc: 1.00000
INFO - 06/15/24 16:13:07 - 0:28:22 - Test: Loss: 1.19212 | Acc: 0.82440
INFO - 06/15/24 16:13:11 - 0:28:26 - Epoch	16
INFO - 06/15/24 16:14:49 - 0:30:04 - Train Loss: 0.0001
INFO - 06/15/24 16:14:49 - 0:30:04 - Val: Loss: 0.00018 | Acc: 1.00000
INFO - 06/15/24 16:14:59 - 0:30:14 - Test: Loss: 1.19028 | Acc: 0.82422
INFO - 06/15/24 16:15:03 - 0:30:18 - Epoch	17
INFO - 06/15/24 16:16:41 - 0:31:56 - Train Loss: 0.0000
INFO - 06/15/24 16:16:41 - 0:31:56 - Val: Loss: 0.00015 | Acc: 1.00000
INFO - 06/15/24 16:16:50 - 0:32:05 - Test: Loss: 1.19042 | Acc: 0.82478
INFO - 06/15/24 16:16:55 - 0:32:10 - Epoch	18
INFO - 06/15/24 16:18:32 - 0:33:47 - Train Loss: 0.0000
INFO - 06/15/24 16:18:32 - 0:33:47 - Val: Loss: 0.00015 | Acc: 1.00000
INFO - 06/15/24 16:18:41 - 0:33:56 - Test: Loss: 1.19235 | Acc: 0.82496
INFO - 06/15/24 16:18:47 - 0:34:02 - Epoch	19
INFO - 06/15/24 16:20:25 - 0:35:40 - Train Loss: 0.0000
INFO - 06/15/24 16:20:25 - 0:35:40 - Val: Loss: 0.00015 | Acc: 1.00000
INFO - 06/15/24 16:20:34 - 0:35:49 - Test: Loss: 1.19278 | Acc: 0.82515
INFO - 06/15/24 16:20:39 - 0:35:54 - Epoch	20
INFO - 06/15/24 16:22:17 - 0:37:32 - Train Loss: 0.0001
INFO - 06/15/24 16:22:17 - 0:37:32 - Val: Loss: 0.00015 | Acc: 1.00000
INFO - 06/15/24 16:22:26 - 0:37:41 - Test: Loss: 1.19285 | Acc: 0.82533
INFO - 06/15/24 16:24:11 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 3
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 13
                                     patience: 10
                                     region_image_embeds: 10
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/15/24 16:24:11 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 16:24:12 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 16:24:12 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 16:24:12 - 0:00:01 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 16:24:14 - 0:00:03 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 16:24:14 - 0:00:03 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 16:24:14 - 0:00:03 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 16:24:15 - 0:00:04 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased.tar.gz HTTP/1.1" 200 0
INFO - 06/15/24 16:24:15 - 0:00:04 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/15/24 16:24:15 - 0:00:04 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpnn_899ci
INFO - 06/15/24 16:24:18 - 0:00:07 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/15/24 16:24:21 - 0:00:10 - Training..
INFO - 06/15/24 16:24:21 - 0:00:10 - Epoch	1
INFO - 06/15/24 16:25:42 - 0:01:31 - Train Loss: 0.0285
INFO - 06/15/24 16:25:42 - 0:01:31 - Val: Loss: 0.39701 | Acc: 0.82227
INFO - 06/15/24 16:25:50 - 0:01:39 - Test: Loss: 0.44070 | Acc: 0.80283
INFO - 06/15/24 16:26:01 - 0:01:50 - Epoch	2
INFO - 06/15/24 16:27:22 - 0:03:11 - Train Loss: 0.0186
INFO - 06/15/24 16:27:22 - 0:03:11 - Val: Loss: 0.22543 | Acc: 0.93232
INFO - 06/15/24 16:27:30 - 0:03:20 - Test: Loss: 0.39200 | Acc: 0.82682
INFO - 06/15/24 16:27:40 - 0:03:30 - Epoch	3
INFO - 06/15/24 16:29:01 - 0:04:50 - Train Loss: 0.0098
INFO - 06/15/24 16:29:01 - 0:04:50 - Val: Loss: 0.07760 | Acc: 0.97994
INFO - 06/15/24 16:29:09 - 0:04:58 - Test: Loss: 0.44819 | Acc: 0.81845
INFO - 06/15/24 16:29:14 - 0:05:03 - Epoch	4
INFO - 06/15/24 16:30:35 - 0:06:24 - Train Loss: 0.0045
INFO - 06/15/24 16:30:35 - 0:06:24 - Val: Loss: 0.03791 | Acc: 0.98856
INFO - 06/15/24 16:30:43 - 0:06:32 - Test: Loss: 0.64807 | Acc: 0.81287
INFO - 06/15/24 16:30:49 - 0:06:38 - Epoch	5
INFO - 06/15/24 16:32:10 - 0:07:59 - Train Loss: 0.0024
INFO - 06/15/24 16:32:10 - 0:07:59 - Val: Loss: 0.01599 | Acc: 0.99569
INFO - 06/15/24 16:32:18 - 0:08:07 - Test: Loss: 0.74580 | Acc: 0.80450
INFO - 06/15/24 16:32:23 - 0:08:12 - Epoch	6
INFO - 06/15/24 16:33:43 - 0:09:32 - Train Loss: 0.0010
INFO - 06/15/24 16:33:43 - 0:09:32 - Val: Loss: 0.00433 | Acc: 0.99906
INFO - 06/15/24 16:33:51 - 0:09:40 - Test: Loss: 0.85466 | Acc: 0.81882
INFO - 06/15/24 16:33:56 - 0:09:46 - Epoch	7
INFO - 06/15/24 16:35:15 - 0:11:05 - Train Loss: 0.0004
INFO - 06/15/24 16:35:15 - 0:11:05 - Val: Loss: 0.00171 | Acc: 0.99944
INFO - 06/15/24 16:35:24 - 0:11:13 - Test: Loss: 0.99021 | Acc: 0.82236
INFO - 06/15/24 16:35:29 - 0:11:18 - Epoch	8
INFO - 06/15/24 16:36:49 - 0:12:39 - Train Loss: 0.0003
INFO - 06/15/24 16:36:49 - 0:12:39 - Val: Loss: 0.00137 | Acc: 0.99963
INFO - 06/15/24 16:36:57 - 0:12:47 - Test: Loss: 1.02393 | Acc: 0.82589
INFO - 06/15/24 16:37:02 - 0:12:52 - Epoch	9
INFO - 06/15/24 16:38:23 - 0:14:12 - Train Loss: 0.0001
INFO - 06/15/24 16:38:23 - 0:14:12 - Val: Loss: 0.00063 | Acc: 0.99981
INFO - 06/15/24 16:38:31 - 0:14:20 - Test: Loss: 1.04726 | Acc: 0.82217
INFO - 06/15/24 16:38:36 - 0:14:25 - Epoch	10
INFO - 06/15/24 16:39:58 - 0:15:47 - Train Loss: 0.0001
INFO - 06/15/24 16:39:58 - 0:15:47 - Val: Loss: 0.00049 | Acc: 0.99981
INFO - 06/15/24 16:40:06 - 0:15:55 - Test: Loss: 1.06920 | Acc: 0.82738
INFO - 06/15/24 16:40:15 - 0:16:05 - Epoch	11
INFO - 06/15/24 16:41:37 - 0:17:26 - Train Loss: 0.0001
INFO - 06/15/24 16:41:37 - 0:17:26 - Val: Loss: 0.00023 | Acc: 1.00000
INFO - 06/15/24 16:41:45 - 0:17:34 - Test: Loss: 1.09123 | Acc: 0.82794
INFO - 06/15/24 16:41:55 - 0:17:44 - Epoch	12
INFO - 06/15/24 16:43:16 - 0:19:05 - Train Loss: 0.0001
INFO - 06/15/24 16:43:16 - 0:19:05 - Val: Loss: 0.00013 | Acc: 1.00000
INFO - 06/15/24 16:43:24 - 0:19:13 - Test: Loss: 1.13283 | Acc: 0.82571
INFO - 06/15/24 16:43:29 - 0:19:19 - Epoch	13
INFO - 06/15/24 16:44:50 - 0:20:39 - Train Loss: 0.0001
INFO - 06/15/24 16:44:50 - 0:20:39 - Val: Loss: 0.00019 | Acc: 1.00000
INFO - 06/15/24 16:44:59 - 0:20:48 - Test: Loss: 1.14490 | Acc: 0.82664
INFO - 06/15/24 16:45:03 - 0:20:52 - Epoch	14
INFO - 06/15/24 16:46:24 - 0:22:14 - Train Loss: 0.0001
INFO - 06/15/24 16:46:24 - 0:22:14 - Val: Loss: 0.00030 | Acc: 0.99981
INFO - 06/15/24 16:46:33 - 0:22:22 - Test: Loss: 1.14689 | Acc: 0.82757
INFO - 06/15/24 16:46:37 - 0:22:26 - Epoch	15
INFO - 06/15/24 16:47:57 - 0:23:46 - Train Loss: 0.0000
INFO - 06/15/24 16:47:57 - 0:23:46 - Val: Loss: 0.00018 | Acc: 1.00000
INFO - 06/15/24 16:48:06 - 0:23:55 - Test: Loss: 1.15129 | Acc: 0.82664
INFO - 06/15/24 16:48:10 - 0:23:59 - Epoch	16
INFO - 06/15/24 16:49:31 - 0:25:20 - Train Loss: 0.0001
INFO - 06/15/24 16:49:31 - 0:25:20 - Val: Loss: 0.00020 | Acc: 1.00000
INFO - 06/15/24 16:49:39 - 0:25:28 - Test: Loss: 1.15628 | Acc: 0.82626
INFO - 06/15/24 16:49:45 - 0:25:34 - Epoch	17
INFO - 06/15/24 16:51:05 - 0:26:54 - Train Loss: 0.0000
INFO - 06/15/24 16:51:05 - 0:26:54 - Val: Loss: 0.00012 | Acc: 1.00000
INFO - 06/15/24 16:51:13 - 0:27:03 - Test: Loss: 1.15954 | Acc: 0.82552
INFO - 06/15/24 16:51:18 - 0:27:08 - Epoch	18
INFO - 06/15/24 16:52:39 - 0:28:28 - Train Loss: 0.0000
INFO - 06/15/24 16:52:39 - 0:28:28 - Val: Loss: 0.00013 | Acc: 1.00000
INFO - 06/15/24 16:52:47 - 0:28:36 - Test: Loss: 1.16012 | Acc: 0.82515
INFO - 06/15/24 16:52:51 - 0:28:40 - Epoch	19
INFO - 06/15/24 16:54:12 - 0:30:01 - Train Loss: 0.0000
INFO - 06/15/24 16:54:12 - 0:30:01 - Val: Loss: 0.00014 | Acc: 1.00000
INFO - 06/15/24 16:54:20 - 0:30:10 - Test: Loss: 1.16101 | Acc: 0.82515
INFO - 06/15/24 16:54:25 - 0:30:14 - Epoch	20
INFO - 06/15/24 16:55:46 - 0:31:35 - Train Loss: 0.0000
INFO - 06/15/24 16:55:46 - 0:31:35 - Val: Loss: 0.00013 | Acc: 1.00000
INFO - 06/15/24 16:55:54 - 0:31:44 - Test: Loss: 1.16120 | Acc: 0.82533
INFO - 06/15/24 17:39:18 - 0:00:00 - batch_sz: 32
                                     bert_model: bert-base-uncased
                                     data_path: /data/rensisi/HMCAN/MTTV/data/
                                     drop_img_percent: 0.0
                                     dropout: 0.1
                                     embed_sz: 300
                                     encoder_layer_num: 6
                                     global_image_embeds: 25
                                     gradient_accumulation_steps: 20
                                     hidden: []
                                     hidden_sz: 768
                                     img_embed_pool_type: avg
                                     img_hidden_sz: 2048
                                     include_bn: True
                                     label_type: 2_way_label
                                     load_checkpoint_path: 
                                     lr: 0.0001
                                     lr_factor: 0.5
                                     lr_patience: 2
                                     max_epochs: 20
                                     max_seq_len: 128
                                     model: mttv
                                     n_workers: 1
                                     name: fakeddit_2_way
                                     num_image_embeds: 35
                                     patience: 10
                                     region_image_embeds: 10
                                     savedir: ./save_fakeddit/fakeddit_2_way
                                     seed: 1
                                     task: fakeddit
                                     warmup: 0.1
                                     weight_classes: 1
DEBUG - 06/15/24 17:39:18 - 0:00:00 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 17:39:19 - 0:00:01 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 17:39:19 - 0:00:01 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 17:39:19 - 0:00:01 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 17:39:21 - 0:00:03 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO - 06/15/24 17:39:21 - 0:00:03 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /data/rensisi/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG - 06/15/24 17:39:21 - 0:00:03 - Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG - 06/15/24 17:39:22 - 0:00:04 - https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased.tar.gz HTTP/1.1" 200 0
INFO - 06/15/24 17:39:22 - 0:00:04 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO - 06/15/24 17:39:22 - 0:00:04 - extracting archive file /data/rensisi/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpu9ronbmx
INFO - 06/15/24 17:39:25 - 0:00:07 - Model config {
                                       "attention_probs_dropout_prob": 0.1,
                                       "hidden_act": "gelu",
                                       "hidden_dropout_prob": 0.1,
                                       "hidden_size": 768,
                                       "initializer_range": 0.02,
                                       "intermediate_size": 3072,
                                       "max_position_embeddings": 512,
                                       "num_attention_heads": 12,
                                       "num_hidden_layers": 12,
                                       "type_vocab_size": 2,
                                       "vocab_size": 30522
                                     }
                                     
INFO - 06/15/24 17:39:29 - 0:00:11 - Training..
INFO - 06/15/24 17:39:29 - 0:00:11 - Epoch	1
INFO - 06/15/24 17:41:21 - 0:02:03 - Train Loss: 0.0297
INFO - 06/15/24 17:41:21 - 0:02:03 - Val: Loss: 0.40747 | Acc: 0.82340
INFO - 06/15/24 17:41:30 - 0:02:13 - Test: Loss: 0.44608 | Acc: 0.79725
INFO - 06/15/24 17:41:40 - 0:02:22 - Epoch	2
INFO - 06/15/24 17:43:32 - 0:04:14 - Train Loss: 0.0196
INFO - 06/15/24 17:43:32 - 0:04:14 - Val: Loss: 0.23696 | Acc: 0.91414
INFO - 06/15/24 17:43:41 - 0:04:23 - Test: Loss: 0.39284 | Acc: 0.82701
INFO - 06/15/24 17:43:50 - 0:04:32 - Epoch	3
INFO - 06/15/24 17:45:42 - 0:06:24 - Train Loss: 0.0109
INFO - 06/15/24 17:45:42 - 0:06:24 - Val: Loss: 0.08248 | Acc: 0.97375
INFO - 06/15/24 17:45:51 - 0:06:33 - Test: Loss: 0.45453 | Acc: 0.82589
INFO - 06/15/24 17:45:55 - 0:06:38 - Epoch	4
INFO - 06/15/24 17:47:48 - 0:08:30 - Train Loss: 0.0044
INFO - 06/15/24 17:47:48 - 0:08:30 - Val: Loss: 0.02174 | Acc: 0.99513
INFO - 06/15/24 17:47:57 - 0:08:39 - Test: Loss: 0.63748 | Acc: 0.82626
INFO - 06/15/24 17:48:02 - 0:08:44 - Epoch	5
INFO - 06/15/24 17:49:54 - 0:10:36 - Train Loss: 0.0019
INFO - 06/15/24 17:49:54 - 0:10:36 - Val: Loss: 0.01308 | Acc: 0.99644
INFO - 06/15/24 17:50:03 - 0:10:45 - Test: Loss: 0.80939 | Acc: 0.81659
INFO - 06/15/24 17:50:08 - 0:10:50 - Epoch	6
INFO - 06/15/24 17:52:00 - 0:12:42 - Train Loss: 0.0009
INFO - 06/15/24 17:52:00 - 0:12:42 - Val: Loss: 0.00472 | Acc: 0.99906
INFO - 06/15/24 17:52:09 - 0:12:51 - Test: Loss: 0.92429 | Acc: 0.81975
INFO - 06/15/24 17:52:14 - 0:12:56 - Epoch	7
INFO - 06/15/24 17:54:06 - 0:14:48 - Train Loss: 0.0003
INFO - 06/15/24 17:54:06 - 0:14:48 - Val: Loss: 0.00134 | Acc: 0.99963
INFO - 06/15/24 17:54:14 - 0:14:57 - Test: Loss: 1.01686 | Acc: 0.82366
INFO - 06/15/24 17:54:20 - 0:15:02 - Epoch	8
INFO - 06/15/24 17:56:12 - 0:16:54 - Train Loss: 0.0002
INFO - 06/15/24 17:56:12 - 0:16:54 - Val: Loss: 0.00134 | Acc: 0.99944
INFO - 06/15/24 17:56:21 - 0:17:03 - Test: Loss: 1.10993 | Acc: 0.81734
INFO - 06/15/24 17:56:26 - 0:17:08 - Epoch	9
INFO - 06/15/24 17:58:18 - 0:19:00 - Train Loss: 0.0002
INFO - 06/15/24 17:58:18 - 0:19:00 - Val: Loss: 0.00024 | Acc: 1.00000
INFO - 06/15/24 17:58:27 - 0:19:09 - Test: Loss: 1.10078 | Acc: 0.82385
INFO - 06/15/24 17:58:32 - 0:19:14 - Epoch	10
INFO - 06/15/24 18:00:24 - 0:21:06 - Train Loss: 0.0001
INFO - 06/15/24 18:00:24 - 0:21:06 - Val: Loss: 0.00023 | Acc: 1.00000
INFO - 06/15/24 18:00:33 - 0:21:15 - Test: Loss: 1.12515 | Acc: 0.82329
INFO - 06/15/24 18:00:38 - 0:21:20 - Epoch	11
INFO - 06/15/24 18:02:29 - 0:23:12 - Train Loss: 0.0001
INFO - 06/15/24 18:02:29 - 0:23:12 - Val: Loss: 0.00028 | Acc: 0.99981
INFO - 06/15/24 18:02:39 - 0:23:21 - Test: Loss: 1.15292 | Acc: 0.82496
INFO - 06/15/24 18:02:43 - 0:23:25 - Epoch	12
INFO - 06/15/24 18:04:35 - 0:25:17 - Train Loss: 0.0000
INFO - 06/15/24 18:04:35 - 0:25:17 - Val: Loss: 0.00026 | Acc: 1.00000
INFO - 06/15/24 18:04:44 - 0:25:26 - Test: Loss: 1.15847 | Acc: 0.82626
INFO - 06/15/24 18:04:49 - 0:25:31 - No improvement. Breaking out of loop.
